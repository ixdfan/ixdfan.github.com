---
author: UCSHELL
comments: true
date: 2014-02-26 12:01:34+00:00
layout: post
slug: epoll%e6%a8%a1%e5%9e%8b%e4%b8%80
title: epoll模型
wordpress_id: 1327
categories:
- 网络编程
tags:
- epoll
---

设想这样的一个场景:
有100万用户同时与一个进程保持TCP连接，而每一时刻只有几十或是几百个TCP连接是活跃的(接收到TCP包)，也就是说在每一个时刻，进程只要处理这100万连接中的一小部分连接，那么如何才能高效的处理这种场景呢？

如果进程每次询问操作系统以便收集有事件发生的TCP连接，那么首先要将这100万个连接告诉操作系统，然后由操作系统找出其中有事件发生的几百个连接，但是这100万个连接中大部分都是没有事件发生的！因此每次收集有事件发生的TCP连接时，都要把这100万连接的套接字传递给操作系统，首先这是从用户态内存到内核态内存的大量复制，而操作系统去寻找这些连接上有没有未处理的事件，将会是巨大的资源浪费，但是之前的select和poll就是这样做的，所以他们最多只能处理几千个并发连接。

epoll并不是这样做的，他在linux内核申请了一个简易的文件系统，将原先的一个select或者poll分成了3部分:

1. **调用epoll_create建立一个epoll对象(在epoll文件系统中为这个句柄分配资源);**

2. **调用epoll_ctl向epoll对象添加这100万个连接的套接字;**

3. **调用epoll_wait收集发生事件的连接**

这样只需要在进程启动时建立一个epoll对象，并在需要的时候向他添加或删除连接就可以了
所以在收集事件时候，epoll\_wait的效率就非常高，因为epoll_wait并没有向操作系统传递这100万个连接，内核也不需要去遍历全部连接。

epoll模型的好处在于他不会随着被监控描述符数目的增长而导致效率急剧下降;
select模型是采用便利扫描来判断每个描述符是否有事件发生，当监控的描述符的数目越多，自然耗时越大，而且由于受系统默认限制(依赖的\_\_FD_SETSIZE宏被定义为1024)，select模型最多能同时监控1024个描述符。
epoll没有以上的缺点，即同时监控的描述符的个数不受限制(其实是受进程可打开文件描述符个数限制，但是这个数字一般比较大，可以通过命令 `cat /proc/sys/fs/file-max`查看);

epoll对事件的响应是触发式的，也就是无需对整个监控描述符列表做扫描，只需要对有事件发生的描述符做处理即可

===========================================================

使用epoll

    
    int epoll_create(int size);
    
    int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
    
    int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
    
    int epoll_pwait(int epfd, struct epoll_event *events, int maxevents, int timeout,
    		 const sigset_t *sigmask);


##### epoll_create:
epoll_create会返回一个句柄，之后epoll的使用都将使用这个句柄来标识。

参数size是告诉epoll所要处理的大致事件数目。

#####注意:
size仅仅是告诉内核这个epoll对象会处理事件的大致数目，而不是能够处理的事件的最大个数，Since Linux 2.6.8, the size argument is ignored, but must begreater than zero;

##### epoll_ctl:
epoll_ctl向epoll对象中添加、修改或者删除感兴趣的事件;

成功则返回，0失败返回-1，此时需要根据errno错误码来判断错误类型

参数epfd是epoll_create返回的句柄;

op取值如下:
    
    EPOLL_CTL_ADD    添加新事件到epoll	
    EPOLL_CTL_MOD    修改epoll中的事件
    EPOLL_CTL_DEL    删除epoll中的事件


fd是带检测的连接套接字

event参数是告诉epoll对什么样的事件感兴趣

    
    struct epoll_event{
    	__uint32_t events;
    	epoll_data_t data;
    };


events的取值如下:

    
    EPOLLIN        表示对应的连接上有数据可以读出(TCP连接的远端主动关闭连接，也相当于可读，因为需要处理发送来的FIN包)
    
    EPOLLOUT       表示对应的连接上可以写入数据发送(主动向上游服务器发起非阻塞的TCP连接，连接建立成功的事件相当于可写事件)
    
    EPOLLRDHUP     表示TCP连接的远端关闭或是半关闭连接
    
    EPOLLPRI       表示对应的连接上有紧急数据需要读取
    
    EPOLLERR       表示对应的连接上发生错误
    
    EPOLLHUP       表示对应的连接被挂起
    
    EPOLLLET       表示将出发方式设置为边缘触发(ET),系统默认为水平触发(LT)
    
    EPOLLONESHOT   表示对这个事件只处理一次，下次需要处理时需重新加入epoll


data成员结构如下:
    
    typedef union epoll_data{
    	void*        ptr;
    	int          fd;
    	uint32_t     u32;
    	uint64_t     u64;
    }epoll_data_t;


epoll_wait:

收集在epoll监控的事件中已经发生的事情，如果epoll中没有任何一个事件发生，则最多等待timeout毫秒后返回。

epoll_wait的返回值表示当前发生的事件个数;

* 如果返回为0则表示本次调用中没有事情发生(等待超时仍然没有事情发生);

* 如果返回-1.则表示出现错误,需要检查errno错误码判断错误类型


epfd是epoll的描述符

events是分配好的epoll_event结构体数组，epoll将会把发生的事件复制到events数组中(**events不可以是空指针**，内核仅仅负责将数据复制到events数组中，不会帮助我们在用户态中分配内存，这样的效率很高)。

maxevents表示本次可以返回的最大事件数目，通常与预先分配的enents数组的大小是相等的;但是不能超过epoll_create的参数size，同时也必须大于0;

timeout表示在没有检测到事件发生时最多等待的时间(单位毫秒)，如果为0,则表示epoll_wait在没有检测到事件发生时会立刻发挥，不会等待(有则获取，没有也不会阻塞等待)，取值-1则表示无限等待

epoll\_wait与epoll\_pwait的区别是epoll_pwait可以通过最后一个参数设置阻塞过程中的信号屏蔽字

    
    ready = epoll_pwait(epfd, &events, maxevents, timeout, &sigmask);
    
    等价于以下调用
    
    sigset_t origmask;
    sigprocmask(SIG_SETMASK, &sigmask, &origmask);
    ready = epoll_wait(epfd, &events, maxevents, timeout);
    sigprocmask(SIG_SETMASK, &origmask, NULL);


注意:不再使用epoll时，必须使用close来关闭句柄

===========================================================

epoll有两种工作模式:**LT(level-triggered)模式和ET(edge-triggered)模式**

默认情况下epoll采用LT模式，同时支持阻塞(block I/O)和非阻塞(no-block I/O)套接字

ET模式的效率比LT的更高一些(高速模式)，但是只支持非阻塞套接字(no-block I/O);

epoll_event中的events参数EPOLLET表示将一个事件改为ET模式;

##### ET与LT模式的区别在于:

1. 当一个新的事件到来时，ET模式下当然可以从epoll\_wait调用中获得这个事件，但是如果这次没有把这个事件对应的套接字缓冲区处理完，在这个套接字没有新的事件再次到来的时，ET模式下是没有办法再次从epoll_wait调用中获取这个事件的;

2. LT模式刚好相反，只要一个事件对应的套接字缓冲区还有数据，就总能从epoll_wait中获得这个事件;因此LT模式下开发epoll应用要简单一些，而ET模式下事件发生时，如果没有彻底将缓冲区数据处理完，则会导致缓冲区中的用户请求得不到响应

* LT模式下，当描述符从未就绪变为就绪时，则内核会持续通知，知道这件事处理完成;
* ET模式下，当描述符从未就绪变为就绪时，则内核通过epoll告诉进程该描述符有事情发生，之后就算进程一直不对这个就绪状态的事件进行任何操作，内核也不会再发送更多的通知(除非，该I/O又有新的事件发生)，也就是说内核仅在I/O描述符状态发生变化的那个突变边缘对进程进行一次通知

举个例子:

假设在进程A和B之间通过pipe P进行通信，那么可能会有如下场景:

1. 进程A将P的读端描述符rfd以ET的方式加入到自己epoll监控中，并调用epoll_wait函数阻塞;
2. 进程B向P的写端写入2KB数据;
3. 进程A的描述符rfd上触发可读事件，因此epoll_wait函数返回;
4. 进程A从描述符上读取1KB的数据;
5. 进程A调用epoll_wait函数;

在第5步中，进程A调用epoll_wait函数后会阻塞而不会处罚可读事件，即便是我们知道当前pipe P中仍然有1KB的数据没有读取，假如此时进程B在等待进程A读完全部数据后给出的响应，而没有写入新的数据，那么将会导致ABBA的"假死锁"异常状态;
假如进程B不管A是否已读完所有数据，进行第6步

6.进程B往P的写端又写入2KB数据

那么此时A进程的epoll_wait函数仍然会捕获rfd上的可读事件

根据边缘触发方式的特性，epoll模型工作在ET模式时，必须使用非阻塞文件描述符，以避免由于一个文件描述符的阻塞读/写操作而导致需处理的其他多个文件描述符人物被"饿死"。

**使用ET模式时候，推荐步骤如下:**

1. 基于非阻塞文件描述符:即将待加入到epoll模型里的描述符都设置为no-block
2. **只有当read()或write()返回EAGIN或是read()或write()读到/写出的数据长度小于请求的数据长度**(对于面向流的文件，例如pipe、FIFO、流套接字)时才需要挂起等待下一个事件，否则可能会出现意想不到的逻辑异常
